from openai import OpenAI
import base64
import io
import os
import time

from PIL import Image
from openai import OpenAI

from config import *
from openai import OpenAI
import os
import base64
import sys
import time  # <--- Êñ∞Â¢û 1: ÂØºÂÖ• time Ê®°Âùó
import mimetypes  # ÂºïÂÖ•Ëøô‰∏™Â∫ìÊù•Ëá™Âä®Âà§Êñ≠Êñá‰ª∂Á±ªÂûã
import json
import re
from config import *
from cv_utils import encode_image_vl, get_type

client = OpenAI(
    api_key="sk-no-key-required",
    base_url="http://localhost:8080/v1"
)

token_count = 0
first_token_time = None
start_gen_time = None


result = ''
# ËÆ∞ÂΩïÂºÄÂßãÂ§ÑÁêÜÁöÑÊó∂Èó¥
start_process_time = time.time()

image_path = "/mnt/d/projects/stock_v2510/src/bottom_reversal_breakout/dataset_3/image1.png"

prompt = """
‰Ω†ÊòØ‰∏ÄÂè∞È´òÁ≤æÂ∫¶ÈáëËûçÂõæÂÉèÊâ´Êèè‰ª™„ÄÇ
‰ªªÂä°ÔºöÂü∫‰∫éËøôÂº†KÁ∫øÂõæÔºåËæìÂá∫ MA5 ‰∏é MA20 ÁöÑ‰∫§ÁÇπÂØπÂ∫îÁöÑÊàê‰∫§Èáè„ÄÇ

Ë¶ÅÊ±ÇÔºö
1) ÊâæÂá∫ MA5 ‰∏é MA20 ÁöÑ‰∫§ÁÇπÂÉèÁ¥†ÂùêÊ†á intersection_pxÔºàÂ∑¶‰∏äËßí‰∏∫(0,0)Ôºâ„ÄÇ
2) Â∞Ü intersection_px.x Êò†Â∞ÑÂà∞ÂØπÂ∫îÁöÑÂΩìÊó•Ëú°ÁÉõ candle_indexÔºà‰ªéÂ∑¶Âà∞Âè≥‰ªé1ÂºÄÂßãÔºâÔºåÂπ∂ÁªôÂá∫ candle_bbox=[ymin,xmin,ymax,xmax]Ôºà‰ªÖÂÆû‰ΩìÊàñÂåÖÂê´ÂΩ±Á∫øÂùáÂèØÔºå‰ΩÜÂøÖÈ°ª‰∏ÄËá¥Ôºâ„ÄÇ
3) ÊâæÂà∞ candle_index ÂØπÂ∫îÁöÑÊàê‰∫§ÈáèÊü± volume_bar_bbox=[ymin,xmin,ymax,xmax]„ÄÇ
4) È¢ùÂ§ñËæìÂá∫‰∫§ÁÇπÊó•Ââç 5 Ê†πKÁ∫øÔºàcandle_index-1 Âà∞ candle_index-5ÔºâÁöÑÊàê‰∫§ÈáèÊü± previous_volume_barsÔºàÊØè‰∏™ÂêåÊ†∑Áªô bboxÔºâ„ÄÇ
5) Â¶ÇÊûúËÉΩËØªÂà∞ÈáèËÉΩÂùêÊ†áËΩ¥ÂàªÂ∫¶ÔºåËØ∑ËæìÂá∫ volume_axis_ticks=[{"y":int,"label":str},...]ÔºàËá≥Â∞ë2‰∏™ÂàªÂ∫¶ÔºåÂåÖÂê´0Êõ¥Â•ΩÔºâ„ÄÇ
6) Â¶ÇÊûúËÉΩÁõ¥Êé•ËØªÂà∞‰∫§ÁÇπÂΩìÊó•Êàê‰∫§ÈáèÊï∞ÂÄºÔºåËæìÂá∫ volume_value_textÔºàÂéüÊ†∑Â≠óÁ¨¶‰∏≤Ôºâ„ÄÇ

‰∏•Ê†ºÂè™ËæìÂá∫ JSONÔºå‰∏çË¶ÅËæìÂá∫‰ªª‰ΩïËß£ÈáäÊÄßÊñáÂ≠ó„ÄÇ
JSON schemaÔºö
{
  "intersection_px": {"x": 0, "y": 0},
  "candle": {"index": 0, "bbox": [0,0,0,0]},
  "volume": {
    "bar_bbox": [0,0,0,0],
    "previous_bars": [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]],
    "axis_ticks": [{"y": 0, "label": "0"}],
    "value_text": ""
  }
}
""".strip()

response = client.chat.completions.create(
    model="qwen3-vl-32b-thinking",
    stop=[
            "<|im_end|>",
            "<|im_start|>",
            "<|im_end|>",
            "<|endoftext|>",
        ],
    temperature=0.0,
    top_p=0.1,
    max_tokens=16384,
    frequency_penalty=0.0,
    presence_penalty=0.0,
    stream=True,
    extra_body={
        "repeat_penalty": 1.0,
        "min_p": 0.05
    },
    # response_format={"type": "json_object"},
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{encode_image_vl(image_path)}"
                    }
                },
            ],
        }
    ],
)

# print(response.choices[0].message.content)

print("ÂõûÁ≠îÔºö", end="", flush=True)
think_content = ""
for chunk in response:
    # print(chunk)
    # print('reasoning_content' , chunk.choices[0].delta)

    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="", flush=True)
        result += chunk.choices[0].delta.content
        token_count += 1
        # ÊçïËé∑Á¨¨‰∏Ä‰∏™ token ÁöÑÊó∂Èó¥
        if first_token_time is None:
            first_token_time = time.time()
            start_gen_time = first_token_time  # ÂºÄÂßãÁîüÊàêÁöÑËÆ°Êó∂Ëµ∑ÁÇπ
            # ËÆ°ÁÆóÈ¶ñÂ≠óÂª∂Ëøü (Time to First Token)
            ttft = first_token_time - start_process_time
    elif hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content is not None:
        print(chunk.choices[0].delta.reasoning_content, end="", flush=True)
        think_content += chunk.choices[0].delta.reasoning_content
        token_count += 1
        # ÊçïËé∑Á¨¨‰∏Ä‰∏™ token ÁöÑÊó∂Èó¥
        if first_token_time is None:
            first_token_time = time.time()
            start_gen_time = first_token_time  # ÂºÄÂßãÁîüÊàêÁöÑËÆ°Êó∂Ëµ∑ÁÇπ
            # ËÆ°ÁÆóÈ¶ñÂ≠óÂª∂Ëøü (Time to First Token)
            ttft = first_token_time - start_process_time

print("\n")
# ÁªìÊùüËÆ°Êó∂
end_time = time.time()
print("\n\n" + "=" * 30)

# --- ÁªüËÆ°ËÆ°ÁÆó ---
if token_count > 0 and start_gen_time:
    # Á∫ØÁîüÊàêËÄóÊó∂ (Êâ£Èô§È¶ñÂ≠óÁ≠âÂæÖÊó∂Èó¥)
    gen_duration = end_time - start_gen_time
    # È¶ñÂ≠óÂª∂Ëøü
    ttft = first_token_time - start_process_time

    # ËÆ°ÁÆóÈÄüÂ∫¶ (Tokens Per Second)
    # Èò≤Ê≠¢Èô§‰ª•0 (ËôΩÁÑ∂‰∏çÂ§™ÂèØËÉΩ)
    speed = token_count / gen_duration if gen_duration > 0 else 0

    print(f"üìä ÁªüËÆ°Êä•Âëä:")
    print(f"   - ÁîüÊàêÈïøÂ∫¶: {token_count} tokens")
    print(f"   - È¶ñÂ≠óÂª∂Ëøü (TTFT): {ttft:.2f} s (È¢ÑÂ§ÑÁêÜËÄóÊó∂)")
    print(f"   - ÁîüÊàêËÄóÊó∂: {gen_duration:.2f} s")
    print(f"   - Âπ≥ÂùáÈÄüÂ∫¶: \033[1;32m{speed:.2f} tokens/s\033[0m")  # ÁªøËâ≤È´ò‰∫ÆÊòæÁ§∫ÈÄüÂ∫¶
else:
    print("Êú™ÁîüÊàêÊúâÊïàÂÜÖÂÆπ„ÄÇ")
print("=" * 30 + "\n")
result = result.strip()
print("ÊúÄÁªàÂõûÂ§çÔºö", result)
print("=" * 30 + "\n")

def _extract_json_object(s):
    s = s.strip()
    try:
        return json.loads(s)
    except Exception:
        pass
    m = re.search(r"\{[\s\S]*\}\s*$", s)
    if not m:
        m = re.search(r"\{[\s\S]*\}", s)
    if not m:
        raise ValueError("no json object found")
    return json.loads(m.group(0))

def _bbox_height(b):
    if not isinstance(b, list) or len(b) != 4:
        return None
    try:
        return max(0.0, float(b[2]) - float(b[0]))
    except Exception:
        return None

def _parse_volume_text(t):
    if t is None:
        return None
    if not isinstance(t, str):
        t = str(t)
    s = t.strip().replace(",", "")
    if not s:
        return None
    mult = 1.0
    if "‰∫ø" in s:
        mult = 1e8
        s = s.replace("‰∫ø", "")
    elif "‰∏á" in s:
        mult = 1e4
        s = s.replace("‰∏á", "")
    try:
        return float(s) * mult
    except Exception:
        return None

try:
    data = _extract_json_object(result)
    candle_idx = data.get("candle", {}).get("index")
    bar_bbox = data.get("volume", {}).get("bar_bbox")
    prev_bars = data.get("volume", {}).get("previous_bars") or []

    bar_h = _bbox_height(bar_bbox)
    prev_hs = [h for h in (_bbox_height(b) for b in prev_bars) if h is not None and h > 0]
    prev_avg = (sum(prev_hs) / len(prev_hs)) if prev_hs else None
    spike_50 = (bar_h is not None and prev_avg is not None and bar_h > prev_avg * 1.5)

    vol_text = data.get("volume", {}).get("value_text")
    vol_value = _parse_volume_text(vol_text)

    summary = {
        "intersection_px": data.get("intersection_px"),
        "candle_index": candle_idx,
        "volume_value_text": vol_text,
        "volume_value_parsed": vol_value,
        "volume_bar_height_px": bar_h,
        "previous_avg_height_px": prev_avg,
        "volume_spike_over_50pct": spike_50,
    }
    print(json.dumps(summary, ensure_ascii=False, indent=2))
except Exception as e:
    print("Ëß£Êûê/Ê†°È™åÂ§±Ë¥•Ôºö", str(e))
    pass
