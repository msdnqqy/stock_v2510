import base64
import io
import os
from re import T
import time

from PIL import Image
from openai import OpenAI

from config import *
from openai import OpenAI
import os
import base64
import sys
import time  # <--- æ–°å¢ 1: å¯¼å…¥ time æ¨¡å—
import mimetypes  # å¼•å…¥è¿™ä¸ªåº“æ¥è‡ªåŠ¨åˆ¤æ–­æ–‡ä»¶ç±»å‹
from config import *


def analyze_image(image_path):
    # --- 1. å¢å¼ºç‰ˆå›¾ç‰‡å¤„ç†å‡½æ•° (é˜²æ­¢åå›¾å¯¼è‡´ 500) ---

    def encode_image(p):
        with open(p, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')


    def get_type(path):
        mime_type_temp, _ = mimetypes.guess_type(path)
        if mime_type_temp is None:
            mime_type_temp = 'image/jpeg'  # é»˜è®¤å›é€€åˆ° jpeg
        return mime_type_temp

    # image_path = './dataset/sample2/img.png'

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {image_path}")
        exit()



    # def get_type(path):
    #     mime_type_temp, _ = mimetypes.guess_type(path)
    #     if mime_type_temp is None:
    #         mime_type_temp = 'image/jpeg'  # é»˜è®¤å›é€€åˆ° jpeg
    #     return mime_type_temp


    client = OpenAI(base_url="http://localhost:8080/v1", api_key="sk-xxx", timeout=6000)

    token_count = 0
    first_token_time = None
    start_gen_time = None

    print("length:",len(encode_image(image_path)))

    prompt="""
    â€œä½ éœ€è¦åŒ–èº«ä¸ºé«˜ç²¾åº¦æ‰«æä»ªã€‚è¯·ä»å·¦å¾€å³ï¼Œä¾æ¬¡æ‰¾å‡ºå›¾ä¸­æ‰€æœ‰çš„èœ¡çƒ›çº¿ã€‚ å¯¹äºæ¯ä¸€æ ¹èœ¡çƒ›çº¿ï¼Œè¯·æŒ‰é¡ºåºç¼–å·å¹¶æä¾›å…¶å½’ä¸€åŒ–åæ ‡ã€‚

    <think>
        æ‰«ææ­¥éª¤æ€è€ƒ
    </think>

    è¾“å‡ºè¦æ±‚:åœ¨è¾“å‡ºä¸­ä¸è¦è¾“å‡ºä»»ä½•æ— å…³å†…å®¹ï¼ŒåŠ¡å¿…ç¡®ä¿ç¼–å·è¿ç»­ï¼Œæœ€åç»Ÿè®¡æ€»æ•°ã€‚
    <output>
    <ref>K1</ref><box>[...]</box> <color>çº¢è‰²è¿˜æ˜¯ç»¿è‰²</color> <solid>ç©ºå¿ƒè¿˜æ˜¯å®å¿ƒ</solid><tag>æŸ±å­çš„æ ‡å·</tag>
    <ref>K2</ref><box>[...]</box> <color>çº¢è‰²è¿˜æ˜¯ç»¿è‰²</color> <solid>ç©ºå¿ƒè¿˜æ˜¯å®å¿ƒ</solid><tag>æŸ±å­çš„æ ‡å·</tag>

    ... 
    </output>
    """

    prompt2="""
    Scanning the Image

I've begun analyzing the stock chart image, image6.png. I'm focusing on accurately identifying and extracting candlestick data. My initial focus is on correctly isolating each candlestick from left to right. Once I've verified my approach, I'll move on to normalizing the coordinates. I'm aiming for a highly precise and reliable scan.

Detailing Candlesticks

I've been meticulously examining the image6.png chart, focusing on individual candlestick characteristics and their associated labels. I've categorized each candlestick by color (red or green), solidity (solid or hollow), and the presence of a red number label. My current analysis reveals twelve distinct candlesticks with corresponding labels ranging from 11 to 22, each precisely identified within the chart's structure.

Defining Output Structure

I'm now focusing on formatting the output data according to the established template: <ref>Kn</ref><box>[ymin, xmin, ymax, xmax]</box> <color>...</color> <solid>...</solid><tag>...</tag>. I've extracted all the necessary details, including candlestick color, solidity, and the associated tag. The coordinates, ranging from roughly 100x100 to 950x950, are being normalized to fit the 1000x1000 image dimensions. My priority now is ensuring the output format is precise and compliant with the given structure.

Confirming Final Candlestick Count

I've revised the candlestick data to reflect image-relative coordinates. After processing, I'm verifying the final tally, ensuring a total of twelve candlesticks are represented in the output data. Now, I'm focusing on ensuring data integrity prior to final output.

Finalizing the Data

I'm now checking the solidity of the candlesticks, confirming they're all solid as observed. I've double-checked all coordinates and tag assignments, from K1 to K12. I'm satisfied that everything is correct. The final output is ready to be produced!
    """
    prompt3 = """
å½“ä½ æŠŠå›¾ç‰‡å’Œè¿™æ®µ Prompt å‘ç»™æˆ‘æ—¶ï¼Œæˆ‘çš„å¤„ç†æµç¨‹å¦‚ä¸‹ï¼š

è§†è§‰é”šå®šï¼š åœ¨åæ ‡ç³»ä¸­è¯†åˆ«å‡ºæ‰€æœ‰ç¬¦åˆâ€œæŸ±çŠ¶+ç»†çº¿â€ç‰¹å¾çš„ç‰©ä½“ã€‚

é€»è¾‘å¯¹é½ï¼š å¯»æ‰¾è¿™äº›ç‰©ä½“ä¸‹æ–¹çš„çº¢è‰²æ•°å­—ï¼Œå¹¶å°†å…¶ä¸è§†è§‰ç‰¹å¾è¿›è¡Œ 1:1 ç»‘å®šã€‚

é¡ºåºæ ¡éªŒï¼š æŒ‰ç…§ X åæ ‡çš„å€¼å¯¹è¯†åˆ«å‡ºçš„ç‰©ä½“è¿›è¡Œé™åºæ’åˆ—ã€‚

ç¿»è¯‘è¾“å‡ºï¼š å°†æ¯ä¸€ä¸ªç‰©ä½“çš„è§†è§‰åŒ…å›´æ¡†ï¼ˆBounding Boxï¼‰è½¬æ¢æˆå½’ä¸€åŒ–åçš„æ•°å­—åºåˆ—ã€‚"""


    prompt4 = """ä½ ç°åœ¨æ˜¯ä¸€ä¸ªé«˜ç²¾åº¦è§†è§‰æå–å¼•æ“ã€‚
ä»»åŠ¡ï¼šè¯†åˆ«å›¾ä¸­çº¢è‰²æ•°å­— 11 åˆ° 22 å¯¹åº”çš„èœ¡çƒ›çº¿å±æ€§ã€‚

è§„åˆ™å®šä¹‰ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
1. è¯†åˆ«é¡ºåºï¼šå¿…é¡»æŒ‰ç…§çº¢è‰²æ•°å­— 11, 12, 13... çš„é€’å¢é¡ºåºè¯†åˆ«ã€‚
2. å±æ€§åˆ¤å®šï¼šç»¿è‰²æŸ±å­ = <color>ç»¿è‰²</color> <solid>å®å¿ƒ</solid>ï¼›çº¢è‰²æŸ±å­ = <color>çº¢è‰²</color>ã€‚
3. åæ ‡è¦æ±‚ï¼šæä¾›èœ¡çƒ›çº¿ï¼ˆå«ä¸Šä¸‹å½±çº¿ï¼‰çš„ [ymin, xmin, ymax, xmax] çš„åæ ‡ã€‚

<think>
1. å®šä½æ•°å­— N çš„ä½ç½®ã€‚
2. å¯»æ‰¾æ•°å­— N å‚ç›´æ­£ä¸Šæ–¹çš„èœ¡çƒ›çº¿å®ä½“ã€‚
3. æµ‹é‡è¯¥å®ä½“çš„è¾¹ç•Œæ¡†ã€‚
4. è®°å½•é¢œè‰²å’Œå¡«å……ã€‚
</think>

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
ç›´æ¥æŒ‰é¡ºåºè¾“å‡ºç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•æ€»ç»“æ€§åºŸè¯ã€‚
<output>
<ref>K1</ref><box>[...]</box> <color>...</color> <tag>æ•°å­— N çš„å€¼</tag>
...
</output>"""
    result = ''
    # è®°å½•å¼€å§‹å¤„ç†çš„æ—¶é—´
    start_process_time = time.time()
    response = client.chat.completions.create(
        max_tokens=16192,  # è§†è§‰ä»»åŠ¡é€šå¸¸éœ€è¦å¤šä¸€ç‚¹ token è¾“å‡º
        stream=True,
        model="qwen3-vl",
        temperature=0.0,  # ä¿æŒä½æ¸©
        top_p=0.1,
        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘åŠ å…¥é‡å¤æƒ©ç½š
        frequency_penalty=1.5,  # é˜²æ­¢å¤è¯»
        presence_penalty=0.1,  # ã€æ”¹ä¸º0ã€‘ä¸è¦æƒ©ç½šè¯é¢˜é‡å¤ï¼ŒJSONéœ€è¦é‡å¤Key
        stop=[
            "<|im_end|>",
            "<|im_start|>",
            "<|im_end|>",  # Qwen æ ‡å‡†ç»“æŸç¬¦
            "<|endoftext|>",  # é€šç”¨ç»“æŸç¬¦
            # "```json",  # é˜²æ­¢å®ƒè¾“å‡ºå®Œä»£ç å—åç»§ç»­åºŸè¯
            # "}"                # ã€ç»æ‹›ã€‘å¦‚æœä½ åªéœ€è¦ä¸€ä¸ª JSONï¼Œå¯ä»¥åœ¨æ£€æµ‹åˆ°å³å¤§æ‹¬å·æ—¶å¼ºåˆ¶åœæ­¢ï¼ˆéœ€æ…ç”¨ï¼Œé˜²æ­¢åµŒå¥—ç»“æ„æœªé—­åˆï¼‰
        ],
        # response_format={"type": "json_object"},
        messages=[
            # {
            #     "role": "system",
            #     # ä½¿ç”¨åŠ å¼ºç‰ˆçš„ Prompt
            #     "content": SYSTEM_PROMPT_2
            # },

            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{get_type(image_path)};base64,{encode_image(image_path)}"
                        }
                    },
                    {
                        "type": "text",
                        # "text": prompt + prompt3
                        "text": prompt4
                    }
                ]
            }
        ],

    )
    print("image_path:", image_path)
    print("å›ç­”ï¼š", end="", flush=True)
    think_content = ""
    for chunk in response:
        # print(chunk)
        # print('reasoning_content' , chunk.choices[0].delta)

        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="", flush=True)
            result += chunk.choices[0].delta.content
            token_count += 1
            # æ•è·ç¬¬ä¸€ä¸ª token çš„æ—¶é—´
            if first_token_time is None:
                first_token_time = time.time()
                start_gen_time = first_token_time  # å¼€å§‹ç”Ÿæˆçš„è®¡æ—¶èµ·ç‚¹
                # è®¡ç®—é¦–å­—å»¶è¿Ÿ (Time to First Token)
                ttft = first_token_time - start_process_time
        elif hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content is not None:
            print(chunk.choices[0].delta.reasoning_content, end="", flush=True)
            think_content += chunk.choices[0].delta.reasoning_content
            token_count += 1
            # æ•è·ç¬¬ä¸€ä¸ª token çš„æ—¶é—´
            if first_token_time is None:
                first_token_time = time.time()
                start_gen_time = first_token_time  # å¼€å§‹ç”Ÿæˆçš„è®¡æ—¶èµ·ç‚¹
                # è®¡ç®—é¦–å­—å»¶è¿Ÿ (Time to First Token)
                ttft = first_token_time - start_process_time

    print("\n")
    # ç»“æŸè®¡æ—¶
    end_time = time.time()
    print("\n\n" + "=" * 30)

    # --- ç»Ÿè®¡è®¡ç®— ---
    if token_count > 0 and start_gen_time:
        # çº¯ç”Ÿæˆè€—æ—¶ (æ‰£é™¤é¦–å­—ç­‰å¾…æ—¶é—´)
        gen_duration = end_time - start_gen_time
        # é¦–å­—å»¶è¿Ÿ
        ttft = first_token_time - start_process_time

        # è®¡ç®—é€Ÿåº¦ (Tokens Per Second)
        # é˜²æ­¢é™¤ä»¥0 (è™½ç„¶ä¸å¤ªå¯èƒ½)
        speed = token_count / gen_duration if gen_duration > 0 else 0

        print(f"ğŸ“Š ç»Ÿè®¡æŠ¥å‘Š:")
        print(f"   - ç”Ÿæˆé•¿åº¦: {token_count} tokens")
        print(f"   - é¦–å­—å»¶è¿Ÿ (TTFT): {ttft:.2f} s (é¢„å¤„ç†è€—æ—¶)")
        print(f"   - ç”Ÿæˆè€—æ—¶: {gen_duration:.2f} s")
        print(f"   - å¹³å‡é€Ÿåº¦: \033[1;32m{speed:.2f} tokens/s\033[0m")  # ç»¿è‰²é«˜äº®æ˜¾ç¤ºé€Ÿåº¦
    else:
        print("æœªç”Ÿæˆæœ‰æ•ˆå†…å®¹ã€‚")
    print("=" * 30 + "\n")
    result = result.strip()
    return result


if __name__ == "__main__":
    image_path = "/mnt/d/projects/stock_v2510/src/bottom_reversal_breakout/dataset_2/image6.png"
    result = analyze_image(image_path)

    # image_path = "/mnt/d/projects/stock_v2510/src/bottom_reversal_breakout/dataset_1/sh600031/frame_000360.jpg"
    # result = analyze_image(image_path)
    print(result)